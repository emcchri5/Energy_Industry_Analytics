---
title: "ENE 434 Lab 5"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
###Getting stuff situated
```{r packages}
if(!require ("pacman")) install.packages("pacman")
library(pacman)
p_load(tidyverse, lubridate, fpp3, dynlm)
```
###loading data & wrangling
```{r data1}
ets = read_csv("http://jmaurit.github.io/analytics/labs/data/eua-price.csv")
colnames(ets) = c("date", "price")
elspot = read_csv("http://jmaurit.github.io/norwayeconomy/data_series/elspot.csv")
```
###aggregating data by month
```{r}
ets["month"] = month(ets$date)
ets["year"] = year(ets$date)
ets
ets_mon = ets %>% group_by(month, year) %>% summarise(
  price = mean(price))

#setting day = 1
ets_mon["day"] = 1

ets_mon = ets_mon %>% arrange(year, month)

ets_mon = ets_mon %>% mutate(date = make_date(year, month, day))
```
###joining datasets
```{r}
power_df = elspot %>% inner_join(ets_mon[c("price", "date")], by="date")
```
###saving it locally (idk why)
```{r}
write_csv(power_df, "/Users/EthanMcChristian/Desktop/Dekstop 09:29/power_df.csv")
```
###looking at power in denmark
```{r}
DK_df = power_df %>% select(DK1, DK2, date, price)
colnames(DK_df) = c("DK1_price", "DK2_price", "date", "ets_price")
```
#$/MWh -> $/KWh
```{r}
DK_df["DK1_price"] = DK_df$DK1_price/1000
DK_df["DK2_price"] = DK_df$DK2_price/1000
```

```{r}
DK_df %>% pivot_longer(-date, names_to="series", values_to = "prices") %>% ggplot(aes(x=date, y=prices, color=series)) + 
  geom_line()
```
###time series formatting
```{r}
DK_df$date = yearmonth(DK_df$date)
DK_ts = as_tsibble(DK_df, index=date)
```
###plotting
```{r}
autoplot(DK_ts, DK1_price)
```
###packageee
```{r}
library(tseries)
```
###Dickey-Fuller Test
```{r}
adf.test(DK_ts$DK1_price)
#close to 5% significance, so take the difference
```
###taking differences
```{r}
DK_ts = DK_ts%>% mutate(
  d_DK1_price = difference(DK1_price)
)

DK_ts = DK_ts %>% dplyr::filter(!is.na(d_DK1_price))
```
###ACF and pACF for serial correlation
```{r}
DK_ts %>% fill_gaps() %>% gg_tsdisplay(d_DK1_price, plot_type='partial')
```
###creating ARIMA models
```{r}
fit1 = DK_ts %>% fill_gaps() %>%
  model(
    arima110 = ARIMA(DK1_price ~ pdq(1,1,0)), #p:AR, d:I, q: MA
    arima011 = ARIMA(DK1_price ~ pdq(0,1,1)),
    automatic = ARIMA(DK1_price)
  )
```
###looking at the ARIMA models
```{r}
fit1
glance(fit1) %>% arrange(AICc)
```
###getting model 011 parameters
```{r}
fit1 %>% select(arima011) %>% report()
```
###getting residuals for first model
```{r}
fit1 %>% select(arima011) %>% 
  gg_tsresiduals()
```
###ACF and pACF of original time series data
```{r}
DK_ts %>%  fill_gaps() %>% gg_tsdisplay(DK1_price, plot_type='partial')
```
###trying with two AR terms
```{r}
fit2 = DK_ts %>% fill_gaps() %>%
  model(
    arima200 = ARIMA(DK1_price ~ pdq(2,0,0)) #p:AR, d:I, q: MA
  )
fit2 %>% report()
fit2 %>% gg_tsresiduals()
```

```{r}
fit1 %>% select(arima011) %>%
  forecast(h=10) %>%
  autoplot(DK_ts)
```
###forecasting using AR2 model
```{r}
fit2 %>%
  forecast(h=10) %>%
  autoplot(DK_ts)
```
##new data
###reading in data
```{r}
cons = read_csv2("http://jmaurit.github.io/analytics/labs/data/consumption-per-country_2019_daily.csv")
```
###asdate
```{r}
cons["date"] = as.Date(cons$date, format="%d/%m/%Y")
```
###tsibble,plot
```{r}
cons_ts = tsibble(cons, index=date)
cons_ts %>% autoplot(NO)
```
###dealing with weekly seasonality data
```{r}
cons_comp = cons_ts %>% model(
  STL(NO ~ trend(window=7) #trend (window =7) to account for 7 "seasons"
      + season(window="periodic")) #no idea what this part is for
) %>% components 

cons_comp %>% autoplot()
```

###
```{r}
cons_comp
```

###taking a seasonal difference rather than first difference
```{r}
cons_ts %>%
  gg_tsdisplay(difference(NO, 7), plot_type='partial') #difference of NO with unit length of 7 (7 days in a season)
```
###ARIMA model 1,0,1 and 0,1,1
```{r}
sfit1 <- cons_ts %>%
  model(
    arima101011 = ARIMA(NO ~ 0 + pdq(1,0,1) + PDQ(0,1,1)),
    auto = ARIMA(NO)
  )
```
###1,0,1
```{r}
sfit1 %>% select(arima101011)%>%  report()
```
###auto
```{r}
sfit1 %>% select(auto)%>%  report()
```
###forecasting 30 days ahead
```{r}
sfit1 %>%  select(auto) %>%  forecast(h=120) %>% autoplot(cons_ts)
```

###looking at seasonal 7 day difference
```{r}
cons_ts =  cons_ts %>% mutate(
   returns = log(NO) %>% difference(7)
 )

 
cons_ts %>% autoplot(returns)
```

###creating a AR model with 1st and 7th lags
```{r}
cons_ts = cons_ts %>% filter(!is.na(returns))

arch_mod1 = cons_ts %>%
  model(
    arima100100 = ARIMA(returns ~ 0 + pdq(1,0,0) + PDQ(1,0,0))
  )

arch_mod1 %>% report()
```
###creating a model for squared residuals
```{r}

resids = arch_mod1 %>% residuals()

resids = resids %>% mutate(
  res_sq = .resid^2
)

arch_reg = resids %>%
  model(
    arima100 = ARIMA(res_sq ~ 0 + pdq(1,0,0) + PDQ(0,0,0))
  )

arch_reg %>% report()
```
###installing fGarch to estimate gARCH models
```{r}
p_load(fGarch)
```
###fitting to an ARMA(1,1) and gARCH(1,1) model
```{r}
cons_ts = cons_ts %>% dplyr::filter(!is.na(returns))
#cons_ts = as_tsibble(cons_ts, index=date) *why is this here?*

garchMod1 = garchFit(~arma(1,1) + garch(1,1), data = cons_ts["returns"], trace = F)
summary(garchMod1)
```
###putting volatility back into the dataframe
```{r}
cons_ts["volatility"] =garchMod1@h.t
```
###graphing volatility
```{r}
ggplot(cons_ts, aes(y = volatility, x = date)) + geom_line(col = '#ff9933') + ylab('Conditional Variance') + xlab('Date')
```

###making a prediction using our ARMA and gARCH model
```{r}
predict1 = predict(garchMod1, 120)
```
###combining to the original dataframe
```{r}
predict1["date"] = seq(as.Date("2020-01-01"), as.Date("2020-01-01")+119, by="days")
cons_fcst = cons_ts %>% full_join(predict1, by="date")

cons_fcst["date"] = as.Date(cons_fcst$date)
```
###plotting predictions with a ribbon
```{r}
cons_fcst %>% 
  ggplot() + 
  geom_line(aes(x=date, y=returns)) +
  geom_line(aes(x=date, y=meanForecast, color="red")) +
  geom_ribbon(aes(x=date, ymin=(meanForecast-2*standardDeviation), ymax=(meanForecast+2*standardDeviation) ), fill="blue", alpha=.2)
```

