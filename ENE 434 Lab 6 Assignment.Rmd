---
title: "ENE 434 Lab 6 Assignment"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#loading in data (lab stuff)

```{r}
if (!require('pacman')) install.packages('pacman')
library(pacman)
p_load(tidyverse, fpp3, lubridate)
```

```{r}
power_df = read_csv("https://raw.githubusercontent.com/emcchri5/codebank/main/power_df.csv")
colnames(power_df)[23] = 'ets_price'
power_df$date = yearmonth(power_df$date)
power_ts = tsibble(power_df, index = date)
power_ts = power_ts %>% mutate(
  DK1 = DK1/1000
)
```
```{r}
#scenarios

#no change in ets price
scen1 = new_data(power_ts, 12) %>% 
  mutate(ets_price = rep(power_ts$ets_price[128],12))

#constant increase of .5EUR
scen2 = new_data(power_ts, 12) %>%
  mutate(
    ets_price = rep(power_ts$ets_price[128],12) + cumsum(rep(.5,12))
         )
```

#Assignment
##Question 1
In a dynamic regression model, it may make sense to include lagged variables as exogenous regressors. In the model of DK1 prices, include both contemporaneous and lagged carbon permit prices. How does this change your model? (You may want to read Ch 10.6 in fpp3).
```{r}
armax3 = power_ts %>% fill_gaps() %>% model(
  modWithEts = ARIMA(DK1 ~ ets_price + pdq(2,1,0)),
  mod_ets_lagged = ARIMA(DK1 ~ ets_price + pdq(2,1,0) +
                lag(ets_price) + lag(ets_price, 2) + lag(ets_price, 3)))
glance(armax3) %>% arrange(AICc) #better fit!!
armax2 = power_ts %>% fill_gaps() %>% model(
  modWithEts = ARIMA(DK1 ~ ets_price + pdq(2,1,0)),
  modWOutEts = ARIMA(DK1 ~ pdq(2,1,0))
  )
```

```{r}
armax3 %>% 
  select(modWithEts) %>%
  gg_tsresiduals()
armax3 %>% 
  select(mod_ets_lagged) %>%
  gg_tsresiduals()
```

```{r}
fcast3 = armax2 %>% select(modWithEts) %>% forecast(new_data=scen1)
fcast4 = armax2 %>% select(modWithEts) %>% forecast(new_data=scen2)
fcast5 = armax3 %>% select(mod_ets_lagged) %>% forecast(new_data=scen1)
fcast6 = armax3 %>% select(mod_ets_lagged) %>% forecast(new_data=scen2)
```

```{r}
fcast3 %>% autoplot(power_ts) #constant carbon prices, ets model (no lags)
fcast4 %>% autoplot(power_ts) #increasing carbon prices, ets model
fcast5 %>% autoplot(power_ts) #constant carbon prices, lagged model
fcast6 %>% autoplot(power_ts) #increasing carbon prices, lagged model
```

##Question 2
From ENTSOE-E or statnett, download hourly consumption data for Norway for 2017 and 2018. Join this with the 2019 data in order to create one long time series for Norwegian consumption. Then model the seasonality in the data (at monthly, weakly and daily level), with fourier terms.
###importing data
```{r}
cons_2017 <- read_csv('https://raw.githubusercontent.com/emcchri5/codebank/main/NO_Energy_Cons_2017.csv')
cons_2018 <- read_csv('https://raw.githubusercontent.com/emcchri5/codebank/main/NO_Energy_Cons_2018.csv')
cons = read_csv2("http://jmaurit.github.io/analytics/labs/data/consumption-no-areas_2019_hourly.csv")
```

###getting hour columns
```{r}
cons_2017 <- cons_2017 %>%
  separate('Time(Local)', sep = ' ', into=c('date','time','timezone')) %>%
  separate(time, sep = ':', into=c('hour', 'minute', 'second'))
cons_2018 <- cons_2018 %>%
   separate('Time(Local)', sep = ' ', into=c('date','time','timezone')) %>%
  separate(time, sep = ':', into=c('hour', 'minute', 'second'))
cons <- cons %>% separate(Hours, sep = '-', into=c('start','end'))
```

###converting hour to numeric
```{r}
cons_2017 <- cons_2017 %>%
  mutate(hour = as.numeric(hour))
cons_2018 <- cons_2018 %>%
  mutate(hour = as.numeric(hour))
```

###binding 2017 and 2018 data (easy part)
```{r}
cons_20178 <- rbind(cons_2017, cons_2018)
cons_20178 <- cons_20178 %>%
  select(date, hour, Consumption)
cons_2019 <- cons %>% 
  select(Date, start, NO)
```

###wrangling date values to be parallel
```{r}
cons_20178 <- cons_20178 %>%
  rename('cons' = 'Consumption')
cons_20178$date <- gsub('\\.', '/', cons_20178$date)
cons_2019$time <- gsub('\\s+', '', cons$start)
cons_2019$hour <- as.numeric(cons_2019$time)
cons_2019 <- cons_2019 %>%
  select(Date, hour, NO) %>%
  rename('date' = 'Date', 'cons' = 'NO')
```
###binding datasets 2017/2018 and 2019, fixing data to tsibble
```{r}
cons_total <- rbind(cons_20178, cons_2019)

cons_total["period"] = dmy_h(paste(cons_total$date, cons_total$hour))

#check for NA's
cons_total[!complete.cases(cons_total), ]
#replace NA's
cons_total[["cons"]][cons_total$period==as_datetime("2019-03-31 02:00:00")] = cons_total[["cons"]][cons_total$period==as_datetime("2019-03-31 01:00:00")]
#check for duplicates
duplicates(cons_total)
#run this 3 times  until duplicates(cons_total is gone)
dupRow = duplicates(cons_total)[2,]
cons_total = cons_total %>% rows_delete(dupRow, by=c("period", 'cons'))
duplicates(cons_total) #should be an empty 0x4 dataframe
cons_total_ts <- cons_total %>%
  tsibble(index=period) %>%
  fill_gaps()
```

```{r}
smod3 = cons_total_ts %>% model(
  fmod7 = ARIMA(cons ~ fourier(period = 24, K = 1) + fourier(period = 24*7, K = 1) + fourier(period = 24*30, K = 1) + fourier (period = 24*365, K=1) + PDQ(0,0,0))
)
glance(smod3)
```

```{r}
forecast <- smod3 %>%
  forecast(h = 24*365)
forecast %>% autoplot(cons_total_ts)
```

##Question 3
Create a VAR model for consumption and prices in 2019 using Danish data (You can find it on ENTSOE_E or at the Danish TSO’s energy data site. Create a 30 day forecast. Load in actual data for january 2020–how does your forecast look? Include wind power in Denmark as a variable. How does this affect the model and forecast?

```{r}
DAN <- read.csv('https://raw.githubusercontent.com/emcchri5/codebank/main/Total%20Load%20Denmark.csv')
DAN <- DAN %>%
  rename('total_load' = 'Actual.Total.Load..MW....CTA.DK', 'datetime' = 'Time..CET.CEST.') %>%
  select(datetime, total_load)
DAN <- DAN %>%  separate('datetime', sep = ' - ', into=c('start','end')) %>%
  separate('start', sep = ' ', into = c('date', 'time')) %>%
  select(-end)
  
DAN
```

```{r}
DAN_price <- read.csv('https://raw.githubusercontent.com/emcchri5/codebank/main/EL_prices_2019.csv')
DAN_price <- DAN_price %>% select("ï..HourUTC","PriceArea","SpotPriceEUR") %>%
  rename(Time = 'ï..HourUTC', price = "SpotPriceEUR") %>%
  filter(PriceArea == 'DK1') %>%
  separate('Time', sep = 'T', into=c('date','time')) %>%
  separate('time', sep = "[+]", into=c('tid','useless')) %>%
  select(-useless,-PriceArea) %>%
  separate('tid', sep = ':', into= c('hour', 'minute','second'))
DAN_price$time <- paste(DAN_price$hour, DAN_price$minute, sep= ":")
DAN_price <- DAN_price %>%
  select(-hour,-minute,-second)
DAN_price
DAN_price <- DAN_price %>%
  separate('date', sep = '-', into = c('year', 'month', 'day'))
DAN_price
DAN_price$dizzy <- paste(DAN_price$day, DAN_price$month, sep = '.')
DAN_price$date <- paste(DAN_price$dizzy, DAN_price$year, sep = '.')
DAN_price <- DAN_price %>%
  select(-year,-month,-day,-dizzy)
```

```{r}
DAN
DAN_price
DAN_data <- left_join(DAN_price, DAN)
DAN_data <- DAN_data %>% 
  separate('time',sep = ':', into = c('hour','minute'))
DAN_data["period"] = dmy_h(paste(DAN_data$date, DAN_data$time))
  
```
cons_total["period"] = dmy_h(paste(cons_total$date, cons_total$hour))
