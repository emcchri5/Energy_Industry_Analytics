---
title: "ENE 434 Lab 6 Assignment"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#loading in data (lab stuff)

```{r}
if (!require('pacman')) install.packages('pacman')
library(pacman)
p_load(tidyverse, fpp3, lubridate)
```

```{r}
power_df = read_csv("https://raw.githubusercontent.com/emcchri5/codebank/main/power_df.csv")
colnames(power_df)[23] = 'ets_price'
power_df$date = yearmonth(power_df$date)
power_ts = tsibble(power_df, index = date)
power_ts = power_ts %>% mutate(
  DK1 = DK1/1000
)
```
```{r}
#scenarios

#no change in ets price
scen1 = new_data(power_ts, 12) %>% 
  mutate(ets_price = rep(power_ts$ets_price[128],12))

#constant increase of .5EUR
scen2 = new_data(power_ts, 12) %>%
  mutate(
    ets_price = rep(power_ts$ets_price[128],12) + cumsum(rep(.5,12))
         )
```

#Assignment
##Question 1
In a dynamic regression model, it may make sense to include lagged variables as exogenous regressors. In the model of DK1 prices, include both contemporaneous and lagged carbon permit prices. How does this change your model? (You may want to read Ch 10.6 in fpp3).
```{r}
armax3 = power_ts %>% fill_gaps() %>% model(
  modWithEts = ARIMA(DK1 ~ ets_price + pdq(2,1,0)),
  mod_ets_lagged = ARIMA(DK1 ~ ets_price + pdq(2,1,0) +
                lag(ets_price) + lag(ets_price, 2) + lag(ets_price, 3)))
glance(armax3) %>% arrange(AICc) #better fit!!
```

```{r}
armax3 %>% 
  select(modWithEts) %>%
  gg_tsresiduals()
armax3 %>% 
  select(mod_ets_lagged) %>%
  gg_tsresiduals()
```

```{r}
fcast5 = armax3 %>% select(mod_ets_lagged) %>% forecast(new_data=scen1)
fcast6 = armax3 %>% select(mod_ets_lagged) %>% forecast(new_data=scen2)
```

```{r}
fcast3 %>% autoplot(power_ts) #constant carbon prices, ets model (no lags)
fcast4 %>% autoplot(power_ts) #increasing carbon prices, ets model
fcast5 %>% autoplot(power_ts) #constant carbon prices, lagged model
fcast6 %>% autoplot(power_ts) #increasing carbon prices, lagged model
```

##Question 2
From ENTSOE-E or statnett, download hourly consumption data for Norway for 2017 and 2018. Join this with the 2019 data in order to create one long time series for Norwegian consumption. Then model the seasonality in the data (at monthly, weakly and daily level), with fourier terms.
```{r}
cons_2017 <- read_csv2('https://raw.githubusercontent.com/emcchri5/codebank/main/NO_Energy_Cons_2017.csv')
cons_2018 <- read_csv2('https://raw.githubusercontent.com/emcchri5/codebank/main/NO_Energy_Cons_2018.csv')
```

```{r}
p_load(tidyverse, lubridate)
cons = read_csv2("http://jmaurit.github.io/analytics/labs/data/consumption-no-areas_2019_hourly.csv")
```

```{r}
cons <- cons %>% seperate(Hours, sep = '-', into=c('start','end'))
```

```{r}
cons %>% select('Date', 'start', 'end', 'NO', 'period')
cons_2017 
#cons["Date"] = as.Date(cons$Date, format="%d/%m/%Y")
cons_2017 = cons_2017 %>% separate('Time(Local)', sep=" ", into=c("date", "time"))
cons_2017
#we use lubridate to create a date-time columns
p_load(lubridate)
cons_2017["period"] = dmy_h(paste(cons_2017$date, cons_2017$time))
#We have one missing value - I will fudge it and replace it with the previous hours value
cons_2017
cons
```


